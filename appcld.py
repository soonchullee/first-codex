import streamlit as st
import pandas as pd
import requests
import json
import plotly.graph_objects as go
import plotly.express as px
from collections import Counter
import re
import datetime
import hashlib
import hmac
import base64
import time
from urllib.parse import quote
import os
from typing import Dict, List, Optional, Tuple
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° (ë³´ì•ˆ ê°•í™”)
NAVER_SEARCH_CLIENT_ID = os.getenv('NAVER_SEARCH_CLIENT_ID', 'LsIevNgInDgJxnW7EEUC')
NAVER_SEARCH_CLIENT_SECRET = os.getenv('NAVER_SEARCH_CLIENT_SECRET', 'SqAhgUjGOG')
NAVER_AD_ACCESS_LICENSE = os.getenv('NAVER_AD_ACCESS_LICENSE', '0100000000b023976c548606bfd54a31b499d1066cd59544d9ace90d87de8da28d33426930')
NAVER_AD_SECRET_KEY = os.getenv('NAVER_AD_SECRET_KEY', 'AQAAAACwI5dsVIYGv9VKMbSZ0QZs246RMlg7Og3b+eFMDgNt3A==')
NAVER_AD_CUSTOMER_ID = os.getenv('NAVER_AD_CUSTOMER_ID', '748791')

class NaverKeywordAnalyzer:
    """ë„¤ì´ë²„ ì‡¼í•‘ í‚¤ì›Œë“œ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.search_headers = {
            'X-Naver-Client-Id': NAVER_SEARCH_CLIENT_ID,
            'X-Naver-Client-Secret': NAVER_SEARCH_CLIENT_SECRET
        }
        
    @st.cache_data(ttl=3600)
    def get_product_count_for_keywords(_self, keywords: List[str], batch_size: int = 5) -> Dict[str, int]:
        """í‚¤ì›Œë“œë³„ ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        url = 'https://openapi.naver.com/v1/search/shop.json'
        product_counts = {}
        
        for i in range(0, len(keywords), batch_size):
            batch = keywords[i:i + batch_size]
            
            for keyword in batch:
                try:
                    params = {'query': keyword, 'display': 1}
                    response = requests.get(
                        url, 
                        headers=_self.search_headers, 
                        params=params, 
                        timeout=10
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        total_count = data.get('total', 0)
                        product_counts[keyword] = total_count
                    else:
                        logger.warning(f"Product count API failed for {keyword}: {response.status_code}")
                        product_counts[keyword] = 0
                        
                    time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©
                    
                except Exception as e:
                    logger.error(f"Error getting product count for {keyword}: {str(e)}")
                    product_counts[keyword] = 0
        
        return product_counts

    def clean_title(self, title: str) -> str:
        """ìƒí’ˆ ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°"""
        # HTML íƒœê·¸ ì œê±°
        title = re.sub(r'<[^>]+>', '', title)
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°
        title = re.sub(r'[\[\](){}ã€ˆã€‰ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘\<\>].*?[\[\](){}ã€ˆã€‰ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘\<\>]', '', title)
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        title = re.sub(r'[^\w\sê°€-í£]', ' ', title)
        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        title = re.sub(r'\s+', ' ', title).strip()
        return title

    def is_valid_keyword(self, word: str, original_keyword: str) -> bool:
        """ìœ íš¨í•œ í‚¤ì›Œë“œì¸ì§€ íŒë‹¨"""
        # ì œì™¸í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ í™•ì¥
        excluded_words = {
            'ìƒí’ˆ', 'ë¬´ë£Œë°°ì†¡', 'ë‹¹ì¼ë°°ì†¡', 'íƒë°°', 'ë„¤ì´ë²„', 'ì¿ íŒ¡', '11ë²ˆê°€',
            'ë°°ì†¡', 'ë¬´ë£Œ', 'í• ì¸', 'ì„¸íŠ¸', 'ê°œì…', 'ê°œë“¤ì´', 'í¬í•¨', 'ì¦ì •',
            'ì´ë²¤íŠ¸', 'íŠ¹ê°€', 'í•œì •', 'ì„ ë¬¼', 'ì‚¬ì€í’ˆ', 'PC', 'TV', 'DVD'
        }
        
        return (
            len(word) >= 2 and 
            word.lower() != original_keyword.lower() and 
            not word.isdigit() and
            word not in excluded_words and
            not re.match(r'^\d+[ê°€-í£]*$', word)  # ìˆ«ì+í•œê¸€ íŒ¨í„´ ì œì™¸ (ì˜ˆ: 1ê°œ, 2ë²ˆì§¸ ë“±)
        )

    def get_related_keywords(self, keyword: str, max_items: int = 100) -> pd.DataFrame:
        """ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        url = 'https://openapi.naver.com/v1/search/shop.json'
        params = {
            'query': keyword, 
            'display': max_items,
            'sort': 'sim'
        }

        try:
            response = requests.get(url, headers=self.search_headers, params=params, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])
                
                if not items:
                    st.warning(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
                
                # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ë¦¬
                all_keywords = []
                for item in items:
                    title = item.get('title', '')
                    cleaned_title = self.clean_title(title)
                    words = cleaned_title.split()

                    for word in words:
                        if self.is_valid_keyword(word, keyword):
                            all_keywords.append(word)

                # í‚¤ì›Œë“œë³„ ë¹ˆë„ìˆ˜ ê³„ì‚°
                keyword_counts = Counter(all_keywords)
                
                if not keyword_counts:
                    st.warning("ìœ ì˜ë¯¸í•œ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
                
                # DataFrameìœ¼ë¡œ ë³€í™˜
                df = pd.DataFrame(keyword_counts.items(), columns=["ì—°ê´€ ê²€ìƒ‰ì–´", "ì–¸ê¸‰ íšŸìˆ˜"])
                df = df.sort_values(by="ì–¸ê¸‰ íšŸìˆ˜", ascending=False).head(40)
                
                # ì¤‘ë³µ ì œê±° ë° ìˆœìœ„ ì¶”ê°€
                df = df.drop_duplicates(subset=['ì—°ê´€ ê²€ìƒ‰ì–´'], keep='first')
                df.reset_index(drop=True, inplace=True)
                df['ìˆœìœ„'] = range(1, len(df) + 1)
                
                return df[['ìˆœìœ„', 'ì—°ê´€ ê²€ìƒ‰ì–´', 'ì–¸ê¸‰ íšŸìˆ˜']]
                
            elif response.status_code == 429:
                st.error("API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                
        except requests.exceptions.Timeout:
            st.error("API í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ê²€ìƒ‰ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
        return pd.DataFrame()

    def create_signature(self, timestamp: str, method: str, uri: str) -> str:
        """ë„¤ì´ë²„ ê´‘ê³  API ì‹œê·¸ë‹ˆì²˜ ìƒì„±"""
        signature_string = f"{timestamp}.{method}.{uri}"
        signature = hmac.new(
            key=NAVER_AD_SECRET_KEY.encode('utf-8'),
            msg=signature_string.encode('utf-8'),
            digestmod=hashlib.sha256
        ).digest()
        return base64.b64encode(signature).decode('utf-8')

    def get_search_volume(self, keywords: str) -> Optional[Dict]:
        """ë„¤ì´ë²„ ê´‘ê³  APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê²€ìƒ‰ëŸ‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        base_url = "https://api.searchad.naver.com"
        uri = "/keywordstool"
        method = "GET"
        
        timestamp = str(int(time.time() * 1000))
        signature = self.create_signature(timestamp, method, uri)
        
        headers = {
            'Content-Type': 'application/json; charset=UTF-8',
            'X-API-KEY': NAVER_AD_ACCESS_LICENSE,
            'X-Customer': str(NAVER_AD_CUSTOMER_ID),
            'X-Timestamp': timestamp,
            'X-Signature': signature
        }
        
        params = {
            'hintKeywords': keywords,
            'showDetail': '1'
        }
        
        try:
            full_url = base_url + uri
            response = requests.get(full_url, headers=headers, params=params, timeout=20)
            
            if response.status_code == 200:
                return response.json()
            else:
                self._handle_api_error(response)
                
        except requests.exceptions.Timeout:
            st.error("â° API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ (20ì´ˆ)")
        except Exception as e:
            st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            
        return None

    def _handle_api_error(self, response):
        """API ì—ëŸ¬ ì²˜ë¦¬"""
        error_messages = {
            401: "ğŸ” ì¸ì¦ ì‹¤íŒ¨: API í‚¤, ì‹œí¬ë¦¿ í‚¤, ê³ ê° IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            403: "ğŸš« ê¶Œí•œ ì—†ìŒ: í•´ë‹¹ ê³ ê° IDì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.",
            429: "â° í˜¸ì¶œ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            400: "ğŸ“ ì˜ëª»ëœ ìš”ì²­: íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        }
        
        st.error(f"âŒ ê´‘ê³  API í˜¸ì¶œ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        if response.status_code in error_messages:
            st.error(error_messages[response.status_code])
        else:
            st.error(f"ì‘ë‹µ ë‚´ìš©: {response.text[:200]}")

def create_enhanced_chart(df: pd.DataFrame) -> go.Figure:
    """í–¥ìƒëœ ì—°ê´€ ê²€ìƒ‰ì–´ ì°¨íŠ¸ ìƒì„±"""
    if df.empty:
        return None
        
    top_15 = df.head(15)
    
    # ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜ ìƒì„±
    colors = px.colors.sequential.Blues_r[:len(top_15)]
    
    fig = go.Figure(data=[
        go.Bar(
            x=top_15['ì–¸ê¸‰ íšŸìˆ˜'],
            y=top_15['ì—°ê´€ ê²€ìƒ‰ì–´'],
            orientation='h',
            marker=dict(
                color=colors,
                line=dict(color='rgba(50, 50, 50, 0.8)', width=1)
            ),
            text=top_15['ì–¸ê¸‰ íšŸìˆ˜'],
            textposition='outside',
            hovertemplate='<b>%{y}</b><br>ì–¸ê¸‰ íšŸìˆ˜: %{x}<extra></extra>'
        )
    ])
    
    fig.update_layout(
        title={
            'text': 'ğŸ“Š ì—°ê´€ ê²€ìƒ‰ì–´ ì–¸ê¸‰ ë¹ˆë„ (Top 15)',
            'x': 0.5,
            'font': {'size': 18}
        },
        xaxis_title='ì–¸ê¸‰ íšŸìˆ˜',
        yaxis_title='ì—°ê´€ ê²€ìƒ‰ì–´',
        height=500,
        yaxis={'categoryorder': 'total ascending'},
        showlegend=False,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(family="Arial", size=12),
        margin=dict(l=20, r=20, t=60, b=20)
    )
    
    return fig

def create_comparison_chart(df: pd.DataFrame) -> go.Figure:
    """ê²€ìƒ‰ëŸ‰ê³¼ ì–¸ê¸‰íšŸìˆ˜ ë¹„êµ ì°¨íŠ¸"""
    if df.empty or 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' not in df.columns:
        return None
    
    # ë°ì´í„°ê°€ ìˆëŠ” í•­ëª©ë§Œ í•„í„°ë§
    valid_data = df[(df['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] > 0) & (df['ì–¸ê¸‰ íšŸìˆ˜'] > 0)].head(10)
    
    if valid_data.empty:
        return None
    
    fig = go.Figure()
    
    # ì–¸ê¸‰ íšŸìˆ˜
    fig.add_trace(go.Scatter(
        x=valid_data['ì—°ê´€ ê²€ìƒ‰ì–´'],
        y=valid_data['ì–¸ê¸‰ íšŸìˆ˜'],
        mode='markers+lines',
        name='ì–¸ê¸‰ íšŸìˆ˜',
        yaxis='y',
        marker=dict(size=10, color='blue'),
        line=dict(color='blue', width=2)
    ))
    
    # ê²€ìƒ‰ëŸ‰
    fig.add_trace(go.Scatter(
        x=valid_data['ì—°ê´€ ê²€ìƒ‰ì–´'],
        y=valid_data['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'],
        mode='markers+lines',
        name='ì›”ê°„ ê²€ìƒ‰ìˆ˜',
        yaxis='y2',
        marker=dict(size=10, color='red'),
        line=dict(color='red', width=2)
    ))
    
    fig.update_layout(
        title='ğŸ“ˆ ì–¸ê¸‰ íšŸìˆ˜ vs ì›”ê°„ ê²€ìƒ‰ìˆ˜ ë¹„êµ',
        xaxis_title='ì—°ê´€ ê²€ìƒ‰ì–´',
        yaxis=dict(title='ì–¸ê¸‰ íšŸìˆ˜', side='left', color='blue'),
        yaxis2=dict(title='ì›”ê°„ ê²€ìƒ‰ìˆ˜', side='right', overlaying='y', color='red'),
        height=400,
        hovermode='x unified',
        legend=dict(x=0.01, y=0.99)
    )
    
    return fig

def main():
    # Streamlit í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="ë„¤ì´ë²„ ì‡¼í•‘ í‚¤ì›Œë“œ ë¶„ì„",
        page_icon="ğŸ›’",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ì»¤ìŠ¤í…€ CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<h1 class="main-header">ğŸ›’ ë„¤ì´ë²„ ì‡¼í•‘ í‚¤ì›Œë“œ ë¶„ì„</h1>', unsafe_allow_html=True)
    st.markdown("### ê´€ì‹¬ ìˆëŠ” ì‡¼í•‘ í‚¤ì›Œë“œì˜ ì—°ê´€ ê²€ìƒ‰ì–´ì™€ ê²€ìƒ‰ëŸ‰ì„ ë¶„ì„í•´ë³´ì„¸ìš”!")

    # ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    analyzer = NaverKeywordAnalyzer()

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        keyword = st.text_input(
            'ğŸ” í‚¤ì›Œë“œ ì…ë ¥', 
            value='',
            help="ë¶„ì„í•˜ê³  ì‹¶ì€ ìƒí’ˆ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ë°˜íŒ”í‹°, ë…¸íŠ¸ë¶, ìš´ë™í™”"
        )
        
        st.subheader("ğŸ“Š ë¶„ì„ ì˜µì…˜")
        show_basic_chart = st.checkbox("ê¸°ë³¸ ì°¨íŠ¸ í‘œì‹œ", value=True)
        show_comparison_chart = st.checkbox("ë¹„êµ ì°¨íŠ¸ í‘œì‹œ", value=False)
        show_search_volume = st.checkbox("ê²€ìƒ‰ëŸ‰ ë°ì´í„° í¬í•¨", value=True)
        
        max_keywords_for_volume = st.slider(
            "ê²€ìƒ‰ëŸ‰ ì¡°íšŒí•  í‚¤ì›Œë“œ ìˆ˜",
            min_value=5,
            max_value=20,
            value=10,
            help="ë” ë§ì€ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ë©´ ì‹œê°„ì´ ë” ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        analyze_button = st.button('ğŸš€ ë¶„ì„ ì‹œì‘', type="primary", use_container_width=True)

    # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
    if 'last_keyword' not in st.session_state:
        st.session_state.last_keyword = ''
    
    keyword_changed = (keyword != st.session_state.last_keyword and keyword.strip() != '')
    should_analyze = analyze_button or keyword_changed
    
    if keyword:
        st.session_state.last_keyword = keyword

    # ë©”ì¸ ë¶„ì„ ë¡œì§
    if should_analyze and keyword:
        # ì§„í–‰ìƒí™© í‘œì‹œ
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        try:
            # 1ë‹¨ê³„: ì—°ê´€ ê²€ìƒ‰ì–´ ë¶„ì„
            status_text.text('ğŸ” ì—°ê´€ ê²€ìƒ‰ì–´ ë¶„ì„ ì¤‘...')
            progress_bar.progress(20)
            
            related_df = analyzer.get_related_keywords(keyword)
            
            if not related_df.empty:
                progress_bar.progress(40)
                
                # ê²°ê³¼ í‘œì‹œìš© ì»¨í…Œì´ë„ˆ
                results_container = st.container()
                
                with results_container:
                    # ì„±ê³µ ë©”ì‹œì§€ì™€ ê¸°ë³¸ í†µê³„
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ“ ë°œê²¬ëœ ì—°ê´€ ê²€ìƒ‰ì–´", f"{len(related_df)}ê°œ")
                    with col2:
                        st.metric("ğŸ”¢ í‰ê·  ì–¸ê¸‰ íšŸìˆ˜", f"{related_df['ì–¸ê¸‰ íšŸìˆ˜'].mean():.1f}")
                    with col3:
                        st.metric("ğŸ† ìµœê³  ì–¸ê¸‰ íšŸìˆ˜", f"{related_df['ì–¸ê¸‰ íšŸìˆ˜'].max()}")
                
                # ì°¨íŠ¸ í‘œì‹œ
                chart_container = st.container()
                with chart_container:
                    if show_basic_chart:
                        basic_chart = create_enhanced_chart(related_df)
                        if basic_chart:
                            st.plotly_chart(basic_chart, use_container_width=True)
                
                # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ìˆ˜ì§‘
                if show_search_volume:
                    status_text.text('ğŸ“Š ê²€ìƒ‰ëŸ‰ ë° ìƒí’ˆìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...')
                    progress_bar.progress(60)
                    
                    # ìƒí’ˆìˆ˜ ì¡°íšŒ
                    related_keywords = related_df['ì—°ê´€ ê²€ìƒ‰ì–´'].head(max_keywords_for_volume).tolist()
                    product_counts = analyzer.get_product_count_for_keywords(related_keywords)
                    progress_bar.progress(70)
                    
                    # ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (ë°°ì¹˜ ì²˜ë¦¬)
                    all_volume_data = []
                    keyword_batches = [related_keywords[i:i + 5] for i in range(0, len(related_keywords), 5)]
                    
                    for i, batch in enumerate(keyword_batches):
                        keywords_str = ','.join(batch)
                        search_volume_data = analyzer.get_search_volume(keywords_str)
                        
                        if search_volume_data and 'keywordList' in search_volume_data:
                            all_volume_data.extend(search_volume_data['keywordList'])
                        
                        progress_bar.progress(70 + (i + 1) * 20 // len(keyword_batches))
                        
                        if i < len(keyword_batches) - 1:
                            time.sleep(1)
                    
                    # ë°ì´í„° ë³‘í•© ë° ì •ë¦¬
                    final_df = self._merge_and_clean_data(analyzer, related_df, all_volume_data, product_counts)
                    
                    # ë¹„êµ ì°¨íŠ¸ í‘œì‹œ
                    if show_comparison_chart:
                        comparison_chart = create_comparison_chart(final_df)
                        if comparison_chart:
                            st.plotly_chart(comparison_chart, use_container_width=True)
                    
                    # ìµœì¢… ê²°ê³¼ í‘œì‹œ
                    self._display_final_results(analyzer, final_df)
                else:
                    # ê²€ìƒ‰ëŸ‰ ì—†ì´ ìƒí’ˆìˆ˜ë§Œ
                    related_keywords = related_df['ì—°ê´€ ê²€ìƒ‰ì–´'].tolist()
                    product_counts = analyzer.get_product_count_for_keywords(related_keywords)
                    
                    if product_counts:
                        product_count_df = pd.DataFrame(list(product_counts.items()), 
                                                      columns=['ì—°ê´€ ê²€ìƒ‰ì–´', 'ìƒí’ˆìˆ˜'])
                        final_df = pd.merge(related_df, product_count_df, on='ì—°ê´€ ê²€ìƒ‰ì–´', how='left')
                        final_df['ìƒí’ˆìˆ˜'] = final_df['ìƒí’ˆìˆ˜'].fillna(0).astype(int)
                        
                        st.subheader("ğŸ“‹ ì—°ê´€ ê²€ìƒ‰ì–´ + ìƒí’ˆìˆ˜ ë¶„ì„ ê²°ê³¼")
                        st.dataframe(final_df, use_container_width=True, hide_index=True)
                    else:
                        st.subheader("ğŸ“‹ ì—°ê´€ ê²€ìƒ‰ì–´ ë¶„ì„ ê²°ê³¼")
                        st.dataframe(related_df, use_container_width=True, hide_index=True)
                
                progress_bar.progress(100)
                status_text.text('âœ… ë¶„ì„ ì™„ë£Œ!')
                time.sleep(1)
                progress_container.empty()
                
            else:
                progress_container.empty()
                st.error("âŒ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                
        except Exception as e:
            progress_container.empty()
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logger.error(f"Analysis error: {str(e)}")
            
    elif should_analyze and not keyword:
        st.error("âš ï¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    else:
        # ì‹œì‘ í™”ë©´
        st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!")
        
        # ìƒ˜í”Œ í‚¤ì›Œë“œ ì œì•ˆ
        st.subheader("ğŸ’­ ì¸ê¸° í‚¤ì›Œë“œ ì œì•ˆ")
        sample_keywords = ['ë°˜íŒ”í‹°', 'ë…¸íŠ¸ë¶', 'ìš´ë™í™”', 'í™”ì¥í’ˆ', 'í•¸ë“œí°ì¼€ì´ìŠ¤', 'í…€ë¸”ëŸ¬', 'ë°±íŒ©']
        
        cols = st.columns(len(sample_keywords))
        for i, sample in enumerate(sample_keywords):
            with cols[i]:
                if st.button(sample, key=f"sample_{i}"):
                    st.session_state['keyword_input'] = sample
                    st.rerun()

    def _merge_and_clean_data(analyzer, related_df, volume_data, product_counts):
        """ë°ì´í„° ë³‘í•© ë° ì •ë¦¬"""
        # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë³€í™˜
        if volume_data:
            volume_df = pd.DataFrame(volume_data)
            merged_df = pd.merge(related_df, volume_df, 
                               left_on='ì—°ê´€ ê²€ìƒ‰ì–´', right_on='relKeyword', how='left')
        else:
            merged_df = related_df.copy()
        
        # ìƒí’ˆìˆ˜ ë°ì´í„° ë³‘í•©
        if product_counts:
            product_count_df = pd.DataFrame(list(product_counts.items()), 
                                          columns=['ì—°ê´€ ê²€ìƒ‰ì–´', 'ìƒí’ˆìˆ˜'])
            merged_df = pd.merge(merged_df, product_count_df, on='ì—°ê´€ ê²€ìƒ‰ì–´', how='left')
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        column_mapping = {
            'monthlyPcQcCnt': 'PC ì›”ê°„ê²€ìƒ‰ìˆ˜',
            'monthlyMobileQcCnt': 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜',
            'compIdx': 'ê²½ìŸê°•ë„'
        }
        merged_df.rename(columns=column_mapping, inplace=True)
        
        # ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
        numeric_columns = ['PC ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ìƒí’ˆìˆ˜']
        for col in numeric_columns:
            if col in merged_df.columns:
                merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce').fillna(0).astype(int)
        
        # ì´ ê²€ìƒ‰ìˆ˜ ê³„ì‚°
        if 'PC ì›”ê°„ê²€ìƒ‰ìˆ˜' in merged_df.columns and 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜' in merged_df.columns:
            merged_df['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] = merged_df['PC ì›”ê°„ê²€ìƒ‰ìˆ˜'] + merged_df['ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜']
        
        return merged_df

    def _display_final_results(analyzer, df):
        """ìµœì¢… ê²°ê³¼ í‘œì‹œ"""
        st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        
        # íƒ­ìœ¼ë¡œ ê²°ê³¼ ë¶„ë¦¬
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ì „ì²´ ê²°ê³¼", "ğŸ” ê²€ìƒ‰ëŸ‰ ìˆëŠ” í‚¤ì›Œë“œ", "ğŸ“ˆ ìƒìœ„ í‚¤ì›Œë“œ ìš”ì•½"])
        
        with tab1:
            display_columns = ['ìˆœìœ„', 'ì—°ê´€ ê²€ìƒ‰ì–´', 'ì–¸ê¸‰ íšŸìˆ˜']
            if 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' in df.columns:
                display_columns.extend(['PC ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'])
            if 'ìƒí’ˆìˆ˜' in df.columns:
                display_columns.append('ìƒí’ˆìˆ˜')
            if 'ê²½ìŸê°•ë„' in df.columns:
                display_columns.append('ê²½ìŸê°•ë„')
            
            available_columns = [col for col in display_columns if col in df.columns]
            st.dataframe(df[available_columns], use_container_width=True, hide_index=True)
        
        with tab2:
            if 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' in df.columns:
                with_volume = df[df['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] > 0]
                if not with_volume.empty:
                    st.dataframe(with_volume[available_columns], use_container_width=True, hide_index=True)
                else:
                    st.info("ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ìˆëŠ” í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        with tab3:
            # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ ìš”ì•½
            top_5 = df.head(5)
            for idx, row in top_5.iterrows():
                with st.expander(f"#{row['ìˆœìœ„']} {row['ì—°ê´€ ê²€ìƒ‰ì–´']} (ì–¸ê¸‰ {row['ì–¸ê¸‰ íšŸìˆ˜']}íšŒ)"):
                    col1, col2 = st.columns(2)
                    with col1:
                        if 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' in row:
                            st.write(f"**ì›”ê°„ ê²€ìƒ‰ìˆ˜:** {row['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜']:,}")
                        if 'ìƒí’ˆìˆ˜' in row:
                            st.write(f"**ìƒí’ˆìˆ˜:** {row['ìƒí’ˆìˆ˜']:,}")
                    with col2:
                        if 'ê²½ìŸê°•ë„' in row:
                            st.write(f"**ê²½ìŸê°•ë„:** {row['ê²½ìŸê°•ë„']}")

    # ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("â„¹ï¸ ì‚¬ìš©ë²• ë° ë„ì›€ë§"):
        st.markdown("""
    # ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("â„¹ï¸ ì‚¬ìš©ë²• ë° ë„ì›€ë§"):
        st.markdown("""
        ### ğŸ“ ì‚¬ìš©ë²•
        1. **í‚¤ì›Œë“œ ì…ë ¥**: ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•˜ê³  ì‹¶ì€ ìƒí’ˆëª…ì´ë‚˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”
           - ì˜ˆì‹œ: "ë°˜íŒ”í‹°", "ë…¸íŠ¸ë¶", "ìš´ë™í™”", "í™”ì¥í’ˆ" ë“±
           - ë„ˆë¬´ êµ¬ì²´ì ì´ê±°ë‚˜ ë¸Œëœë“œëª…ë³´ë‹¤ëŠ” ì¼ë°˜ì ì¸ ìƒí’ˆ ì¹´í…Œê³ ë¦¬ê°€ ì¢‹ìŠµë‹ˆë‹¤
        
        2. **ë¶„ì„ ì˜µì…˜ ì„ íƒ**: 
           - **ê¸°ë³¸ ì°¨íŠ¸**: ì—°ê´€ ê²€ìƒ‰ì–´ì˜ ì–¸ê¸‰ ë¹ˆë„ë¥¼ ë§‰ëŒ€ ì°¨íŠ¸ë¡œ í‘œì‹œ
           - **ë¹„êµ ì°¨íŠ¸**: ì–¸ê¸‰ íšŸìˆ˜ì™€ ì›”ê°„ ê²€ìƒ‰ìˆ˜ë¥¼ í•¨ê»˜ ë¹„êµ
           - **ê²€ìƒ‰ëŸ‰ ë°ì´í„°**: ë„¤ì´ë²„ ê´‘ê³  APIë¥¼ í†µí•œ ì‹¤ì œ ê²€ìƒ‰ëŸ‰ ë°ì´í„° í¬í•¨
           - **ê²€ìƒ‰ëŸ‰ ì¡°íšŒ í‚¤ì›Œë“œ ìˆ˜**: API í•œë„ë¥¼ ê³ ë ¤í•˜ì—¬ ì¡°ì ˆ ê°€ëŠ¥ (5-20ê°œ)
        
        3. **ë¶„ì„ ì‹¤í–‰**: 'ğŸš€ ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”
        
        4. **ê²°ê³¼ í™•ì¸**: 4ê°€ì§€ íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
           - **ì¹´ë“œí˜• ë³´ê¸°**: ìŠ¤í¬ë¡¤ ì—†ì´ í˜ì´ì§€ë³„ë¡œ ë³´ê¸° í¸í•œ í˜•íƒœ
           - **í…Œì´ë¸” ë³´ê¸°**: í•„í„°ë§ê³¼ ì •ë ¬ì´ ê°€ëŠ¥í•œ í‘œ í˜•íƒœ
           - **ê²€ìƒ‰ëŸ‰ ë¶„ì„**: ê²€ìƒ‰ëŸ‰ êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„
           - **ì¢…í•© ë¦¬í¬íŠ¸**: ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ì™€ ì¶”ì²œì‚¬í•­
        
        ### ğŸ“Š ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
        
        #### ì£¼ìš” ì§€í‘œ ì„¤ëª…:
        - **ì–¸ê¸‰ íšŸìˆ˜**: ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ê²°ê³¼ ìƒí’ˆëª…ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œê°€ ì–¸ê¸‰ëœ íšŸìˆ˜
        - **ì›”ê°„ê²€ìƒ‰ìˆ˜**: ë„¤ì´ë²„ì—ì„œ ì‹¤ì œë¡œ ê²€ìƒ‰ë˜ëŠ” ì›”í‰ê·  íšŸìˆ˜ (PC + ëª¨ë°”ì¼)
        - **ìƒí’ˆìˆ˜**: í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í–ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆì˜ ì´ ê°œìˆ˜
        - **ê²½ìŸê°•ë„**: ê´‘ê³  ê²½ìŸ ì •ë„ (0-100, ë†’ì„ìˆ˜ë¡ ê²½ìŸ ì¹˜ì—´)
        
        #### ë§ˆì¼€íŒ… í™œìš©ë²•:
        - **ì–¸ê¸‰ íšŸìˆ˜ê°€ ë†’ì€ í‚¤ì›Œë“œ**: ì‹¤ì œ íŒë§¤ìë“¤ì´ ë§ì´ ì‚¬ìš©í•˜ëŠ” í•«í•œ í‚¤ì›Œë“œ
        - **ê²€ìƒ‰ëŸ‰ì´ ë†’ì€ í‚¤ì›Œë“œ**: ê³ ê°ë“¤ì´ ì‹¤ì œë¡œ ë§ì´ ê²€ìƒ‰í•˜ëŠ” í‚¤ì›Œë“œ - ê´‘ê³  í‚¤ì›Œë“œë¡œ í™œìš©
        - **ê²½ìŸê°•ë„ê°€ ë‚®ì€ í‚¤ì›Œë“œ**: ì§„ì…í•˜ê¸° ì‰¬ìš´ í‹ˆìƒˆ í‚¤ì›Œë“œ - SEO ì „ëµì— í™œìš©
        - **ìƒí’ˆìˆ˜ê°€ ì ì€ í‚¤ì›Œë“œ**: ê²½ìŸì´ ì ì–´ ìƒìœ„ ë…¸ì¶œ ê¸°íšŒê°€ ë†’ì€ í‚¤ì›Œë“œ
        
        ### âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ì œí•œì‚¬í•­
        
        #### ë°ì´í„° íŠ¹ì„±:
        - ì—°ê´€ ê²€ìƒ‰ì–´ëŠ” ìµœëŒ€ 40ê°œê¹Œì§€ í‘œì‹œë©ë‹ˆë‹¤
        - ê²€ìƒ‰ëŸ‰ ë°ì´í„°ëŠ” ì„ íƒí•œ ê°œìˆ˜ë§Œí¼ë§Œ ì¡°íšŒë©ë‹ˆë‹¤ (API í•œë„ ê³ ë ¤)
        - ì¼ë¶€ í‚¤ì›Œë“œëŠ” ë„¤ì´ë²„ ê´‘ê³ ì—ì„œ ì§€ì›í•˜ì§€ ì•Šì•„ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - ëª¨ë“  ë°ì´í„°ëŠ” ì›”ê°„ í‰ê·  ê¸°ì¤€ì´ë©° ì‹¤ì‹œê°„ ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤
        
        #### ìµœì  ì‚¬ìš© íŒ:
        - ì²˜ìŒì—ëŠ” ê²€ìƒ‰ëŸ‰ ì¡°íšŒ í‚¤ì›Œë“œ ìˆ˜ë¥¼ ì ê²Œ(5-10ê°œ) ì„¤ì •í•˜ì—¬ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”
        - ì—¬ëŸ¬ ë¹„ìŠ·í•œ í‚¤ì›Œë“œë¡œ ë¶„ì„í•˜ì—¬ íŠ¸ë Œë“œë¥¼ íŒŒì•…í•´ë³´ì„¸ìš”
        - ì •ê¸°ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë³€í™”ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”
        
        #### API ê´€ë ¨:
        - ë„¤ì´ë²„ ê²€ìƒ‰ APIì™€ ê´‘ê³  APIë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ í˜¸ì¶œ í•œë„ê°€ ìˆìŠµë‹ˆë‹¤
        - ì—°ì†ì ì¸ ë¶„ì„ ì‹œ ì ì‹œ ê¸°ë‹¤ë¦° í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
        - API ì˜¤ë¥˜ ë°œìƒ ì‹œ í‚¤ì›Œë“œë¥¼ ë°”ê¾¸ì–´ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”
        
        ### ğŸ’¡ í™œìš© ì‹œë‚˜ë¦¬ì˜¤
        
        #### ì‡¼í•‘ëª° ìš´ì˜ì:
        - ì‹ ìƒí’ˆ ì¶œì‹œ ì „ ê´€ë ¨ í‚¤ì›Œë“œ íŠ¸ë Œë“œ íŒŒì•…
        - ìƒí’ˆëª… ìµœì í™”ë¥¼ ìœ„í•œ ì¸ê¸° í‚¤ì›Œë“œ ë°œêµ´
        - ê´‘ê³  í‚¤ì›Œë“œ ì„ ì • ë° ì˜ˆì‚° ë°°ë¶„ ì°¸ê³ ìë£Œ
        
        #### ë§ˆì¼€í„°:
        - ì½˜í…ì¸  ë§ˆì¼€íŒ… í‚¤ì›Œë“œ ë°œêµ´
        - SEO ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•œ í‚¤ì›Œë“œ ë¦¬ì„œì¹˜
        - ê²½ìŸì‚¬ ë¶„ì„ ë° ì‹œì¥ íŠ¸ë Œë“œ íŒŒì•…
        
        #### ê°œì¸ íŒë§¤ì:
        - íŒë§¤í•  ìƒí’ˆì˜ ì‹œì¥ì„± ê²€ì¦
        - ìƒí’ˆ ì„¤ëª… ì‘ì„± ì‹œ í¬í•¨í•  í‚¤ì›Œë“œ ì„ ì •
        - ë„¤ì´ë²„ ì‡¼í•‘ ìµœì í™” ì „ëµ ìˆ˜ë¦½
        """)


if __name__ == "__main__":
    main()