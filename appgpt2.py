import streamlit as st
import pandas as pd
import requests
import json
import plotly.graph_objects as go
import plotly.express as px
from collections import Counter
import re
import datetime
import hashlib
import hmac
import base64
import time
from urllib.parse import quote
import os
from typing import Dict, List, Optional, Tuple
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° (ë³´ì•ˆ ê°•í™”)
NAVER_SEARCH_CLIENT_ID = os.getenv('NAVER_SEARCH_CLIENT_ID', 'LsIevNgInDgJxnW7EEUC')
NAVER_SEARCH_CLIENT_SECRET = os.getenv('NAVER_SEARCH_CLIENT_SECRET', 'SqAhgUjGOG')
NAVER_AD_ACCESS_LICENSE = os.getenv('NAVER_AD_ACCESS_LICENSE', '0100000000859694c937668dd701fcb3aeff2c3ab8391a20d5d5cec6ca29aade23fddb6975')
NAVER_AD_SECRET_KEY = os.getenv('NAVER_AD_SECRET_KEY', 'AQAAAAAXL8UcMJRZ+X6l38kLGJAQYW5sMh90+zSzf3umtq10cQ==')
NAVER_AD_CUSTOMER_ID = os.getenv('NAVER_AD_CUSTOMER_ID', '748791')

class NaverKeywordAnalyzer:
    """ë„¤ì´ë²„ ì‡¼í•‘ í‚¤ì›Œë“œ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.search_headers = {
            'X-Naver-Client-Id': NAVER_SEARCH_CLIENT_ID,
            'X-Naver-Client-Secret': NAVER_SEARCH_CLIENT_SECRET
        }
        
    @st.cache_data(ttl=3600)
    def get_product_count_for_keywords(_self, keywords: List[str], batch_size: int = 5) -> Dict[str, int]:
        """í‚¤ì›Œë“œë³„ ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        url = 'https://openapi.naver.com/v1/search/shop.json'
        product_counts = {}
        
        for i in range(0, len(keywords), batch_size):
            batch = keywords[i:i + batch_size]
            
            for keyword in batch:
                try:
                    params = {'query': keyword, 'display': 1}
                    response = requests.get(
                        url, 
                        headers=_self.search_headers, 
                        params=params, 
                        timeout=10
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        total_count = data.get('total', 0)
                        product_counts[keyword] = total_count
                    else:
                        logger.warning(f"Product count API failed for {keyword}: {response.status_code}")
                        product_counts[keyword] = 0
                        
                    time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©
                    
                except Exception as e:
                    logger.error(f"Error getting product count for {keyword}: {str(e)}")
                    product_counts[keyword] = 0
        
        return product_counts

    def clean_title(self, title: str) -> str:
        """ìƒí’ˆ ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°"""
        # HTML íƒœê·¸ ì œê±°
        title = re.sub(r'<[^>]+>', '', title)
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°
        title = re.sub(r'[\[\](){}ã€ˆã€‰ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘\<\>].*?[\[\](){}ã€ˆã€‰ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘\<\>]', '', title)
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        title = re.sub(r'[^\w\sê°€-í£]', ' ', title)
        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        title = re.sub(r'\s+', ' ', title).strip()
        return title

    def is_valid_keyword(self, word: str, original_keyword: str) -> bool:
        """ìœ íš¨í•œ í‚¤ì›Œë“œì¸ì§€ íŒë‹¨"""
        # ì œì™¸í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ í™•ì¥
        excluded_words = {
            'ìƒí’ˆ', 'ë¬´ë£Œë°°ì†¡', 'ë‹¹ì¼ë°°ì†¡', 'íƒë°°', 'ë„¤ì´ë²„', 'ì¿ íŒ¡', '11ë²ˆê°€',
            'ë°°ì†¡', 'ë¬´ë£Œ', 'í• ì¸', 'ì„¸íŠ¸', 'ê°œì…', 'ê°œë“¤ì´', 'í¬í•¨', 'ì¦ì •',
            'ì´ë²¤íŠ¸', 'íŠ¹ê°€', 'í•œì •', 'ì„ ë¬¼', 'ì‚¬ì€í’ˆ', 'PC', 'TV', 'DVD'
        }
        
        return (
            len(word) >= 2 and 
            word.lower() != original_keyword.lower() and 
            not word.isdigit() and
            word not in excluded_words and
            not re.match(r'^\d+[ê°€-í£]*$', word)  # ìˆ«ì+í•œê¸€ íŒ¨í„´ ì œì™¸ (ì˜ˆ: 1ê°œ, 2ë²ˆì§¸ ë“±)
        )

    def get_related_keywords(self, keyword: str, max_items: int = 100) -> pd.DataFrame:
        """ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        url = 'https://openapi.naver.com/v1/search/shop.json'
        params = {
            'query': keyword, 
            'display': max_items,
            'sort': 'sim'
        }

        try:
            response = requests.get(url, headers=self.search_headers, params=params, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])
                
                if not items:
                    st.warning(f"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
                
                # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ë¦¬
                all_keywords = []
                for item in items:
                    title = item.get('title', '')
                    cleaned_title = self.clean_title(title)
                    words = cleaned_title.split()

                    for word in words:
                        if self.is_valid_keyword(word, keyword):
                            all_keywords.append(word)

                # í‚¤ì›Œë“œë³„ ë¹ˆë„ìˆ˜ ê³„ì‚°
                keyword_counts = Counter(all_keywords)
                
                if not keyword_counts:
                    st.warning("ìœ ì˜ë¯¸í•œ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
                
                # DataFrameìœ¼ë¡œ ë³€í™˜
                df = pd.DataFrame(keyword_counts.items(), columns=["ì—°ê´€ ê²€ìƒ‰ì–´", "ì–¸ê¸‰ íšŸìˆ˜"])
                
                # ë°ì´í„° íƒ€ì… ì•ˆì „í•˜ê²Œ ë³€í™˜
                df['ì–¸ê¸‰ íšŸìˆ˜'] = pd.to_numeric(df['ì–¸ê¸‰ íšŸìˆ˜'], errors='coerce').fillna(1)
                df['ì–¸ê¸‰ íšŸìˆ˜'] = df['ì–¸ê¸‰ íšŸìˆ˜'].astype(int)
                
                # ì •ë ¬ ë° ìˆœìœ„ ì¶”ê°€
                df = df.sort_values(by="ì–¸ê¸‰ íšŸìˆ˜", ascending=False).head(40)
                df = df[df['ì–¸ê¸‰ íšŸìˆ˜'] > 0].reset_index(drop=True)  # 0ë³´ë‹¤ í° ê°’ë§Œ í•„í„°ë§
                df['ìˆœìœ„'] = range(1, len(df) + 1)
                
                return df[['ìˆœìœ„', 'ì—°ê´€ ê²€ìƒ‰ì–´', 'ì–¸ê¸‰ íšŸìˆ˜']]
                
            elif response.status_code == 429:
                st.error("API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                
        except requests.exceptions.Timeout:
            st.error("API í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ê²€ìƒ‰ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"API Error Details: {str(e)}")
            
        return pd.DataFrame()

    def create_signature(self, timestamp: str, method: str, uri: str) -> str:
        """ë„¤ì´ë²„ ê´‘ê³  API ì‹œê·¸ë‹ˆì²˜ ìƒì„±"""
        signature_string = f"{timestamp}.{method}.{uri}"
        signature = hmac.new(
            key=NAVER_AD_SECRET_KEY.encode('utf-8'),
            msg=signature_string.encode('utf-8'),
            digestmod=hashlib.sha256
        ).digest()
        return base64.b64encode(signature).decode('utf-8')

    def get_search_volume(self, keywords: str) -> Optional[Dict]:
        """ë„¤ì´ë²„ ê´‘ê³  APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê²€ìƒ‰ëŸ‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        # API ê¶Œí•œ í™•ì¸ì„ ìœ„í•œ ì²´í¬
        if not all([NAVER_AD_ACCESS_LICENSE, NAVER_AD_SECRET_KEY, NAVER_AD_CUSTOMER_ID]):
            st.warning("ë„¤ì´ë²„ ê´‘ê³  API ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ìƒ‰ëŸ‰ ë°ì´í„°ëŠ” ì œì™¸í•˜ê³  ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            return None
            
        base_url = "https://api.searchad.naver.com"
        uri = "/keywordstool"
        method = "GET"
        
        timestamp = str(int(time.time() * 1000))
        signature = self.create_signature(timestamp, method, uri)
        
        headers = {
            'Content-Type': 'application/json; charset=UTF-8',
            'X-API-KEY': NAVER_AD_ACCESS_LICENSE,
            'X-Customer': str(NAVER_AD_CUSTOMER_ID),
            'X-Timestamp': timestamp,
            'X-Signature': signature
        }
        
        params = {
            'hintKeywords': keywords,
            'showDetail': '1'
        }
        
        try:
            full_url = base_url + uri
            response = requests.get(full_url, headers=headers, params=params, timeout=20)
            
            if response.status_code == 200:
                return response.json()
            else:
                self._handle_api_error(response)
                # 403 ì—ëŸ¬ ì‹œì—ëŠ” None ë°˜í™˜í•˜ì—¬ ê²€ìƒ‰ëŸ‰ ì—†ì´ ì§„í–‰
                if response.status_code == 403:
                    st.info("ê´‘ê³  API ê¶Œí•œ ë¬¸ì œë¡œ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì—†ì´ ë¶„ì„ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                    return None
                
        except requests.exceptions.Timeout:
            st.error("API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ (20ì´ˆ)")
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            
        return None

    def _handle_api_error(self, response):
        """API ì—ëŸ¬ ì²˜ë¦¬"""
        # 403 ì—ëŸ¬ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬ (ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€)
        if response.status_code == 403:
            # ì„¸ì…˜ ìƒíƒœë¡œ í•œ ë²ˆë§Œ í‘œì‹œ
            if 'api_error_shown' not in st.session_state:
                st.session_state.api_error_shown = True
                # ì¡°ìš©íˆ ë¡œê·¸ì—ë§Œ ê¸°ë¡
                logger.warning("Naver Ad API 403 permission error")
            return
            
        error_messages = {
            401: "ì¸ì¦ ì‹¤íŒ¨: API í‚¤ë‚˜ ì‹œí¬ë¦¿ í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            429: "í˜¸ì¶œ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            400: "ì˜ëª»ëœ ìš”ì²­: íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        }
        
        st.error(f"ê´‘ê³  API í˜¸ì¶œ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        if response.status_code in error_messages:
            st.error(error_messages[response.status_code])
        else:
            st.error(f"ì‘ë‹µ ë‚´ìš©: {response.text[:200]}")

def create_enhanced_chart(df: pd.DataFrame) -> go.Figure:
    """í–¥ìƒëœ ì—°ê´€ ê²€ìƒ‰ì–´ ì°¨íŠ¸ ìƒì„±"""
    if df.empty:
        return None
        
    top_15 = df.head(15)
    
    # ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜ ìƒì„±
    if len(top_15) > len(px.colors.sequential.Blues_r):
        colors = px.colors.sequential.Blues_r
    else:
        colors = px.colors.sequential.Blues_r[:len(top_15)]
    
    fig = go.Figure(data=[
        go.Bar(
            x=top_15['ì–¸ê¸‰ íšŸìˆ˜'],
            y=top_15['ì—°ê´€ ê²€ìƒ‰ì–´'],
            orientation='h',
            marker=dict(
                color=colors,
                line=dict(color='rgba(50, 50, 50, 0.8)', width=1)
            ),
            text=top_15['ì–¸ê¸‰ íšŸìˆ˜'],
            textposition='outside',
            hovertemplate='<b>%{y}</b><br>ì–¸ê¸‰ íšŸìˆ˜: %{x}<extra></extra>'
        )
    ])
    
    fig.update_layout(
        title={
            'text': 'ì—°ê´€ ê²€ìƒ‰ì–´ ì–¸ê¸‰ ë¹ˆë„ (Top 15)',
            'x': 0.5,
            'font': {'size': 18}
        },
        xaxis_title='ì–¸ê¸‰ íšŸìˆ˜',
        yaxis_title='ì—°ê´€ ê²€ìƒ‰ì–´',
        height=500,
        yaxis={'categoryorder': 'total ascending'},
        showlegend=False,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(family="Arial", size=12),
        margin=dict(l=20, r=20, t=60, b=20)
    )
    
    return fig

def create_comparison_chart(df: pd.DataFrame) -> go.Figure:
    """ê²€ìƒ‰ëŸ‰ê³¼ ì–¸ê¸‰íšŸìˆ˜ ë¹„êµ ì°¨íŠ¸"""
    if df.empty or 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' not in df.columns:
        return None
    
    # ì•ˆì „í•œ ë°ì´í„° í•„í„°ë§
    try:
        # ìˆ«ìí˜• ë°ì´í„°ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
        df_clean = df.copy()
        df_clean['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] = pd.to_numeric(df_clean['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'], errors='coerce').fillna(0)
        df_clean['ì–¸ê¸‰ íšŸìˆ˜'] = pd.to_numeric(df_clean['ì–¸ê¸‰ íšŸìˆ˜'], errors='coerce').fillna(0)
        
        valid_data = df_clean[(df_clean['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] > 0) & (df_clean['ì–¸ê¸‰ íšŸìˆ˜'] > 0)].head(10)
        
        if valid_data.empty:
            return None
        
        fig = go.Figure()
        
        # ì–¸ê¸‰ íšŸìˆ˜
        fig.add_trace(go.Scatter(
            x=valid_data['ì—°ê´€ ê²€ìƒ‰ì–´'],
            y=valid_data['ì–¸ê¸‰ íšŸìˆ˜'],
            mode='markers+lines',
            name='ì–¸ê¸‰ íšŸìˆ˜',
            yaxis='y',
            marker=dict(size=10, color='blue'),
            line=dict(color='blue', width=2)
        ))
        
        # ê²€ìƒ‰ëŸ‰
        fig.add_trace(go.Scatter(
            x=valid_data['ì—°ê´€ ê²€ìƒ‰ì–´'],
            y=valid_data['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'],
            mode='markers+lines',
            name='ì›”ê°„ ê²€ìƒ‰ìˆ˜',
            yaxis='y2',
            marker=dict(size=10, color='red'),
            line=dict(color='red', width=2)
        ))
        
        fig.update_layout(
            title='ì–¸ê¸‰ íšŸìˆ˜ vs ì›”ê°„ ê²€ìƒ‰ìˆ˜ ë¹„êµ',
            xaxis_title='ì—°ê´€ ê²€ìƒ‰ì–´',
            yaxis=dict(title='ì–¸ê¸‰ íšŸìˆ˜', side='left', color='blue'),
            yaxis2=dict(title='ì›”ê°„ ê²€ìƒ‰ìˆ˜', side='right', overlaying='y', color='red'),
            height=400,
            hovermode='x unified',
            legend=dict(x=0.01, y=0.99)
        )
        
        return fig
        
    except Exception as e:
        logger.error(f"Chart creation error: {str(e)}")
        return None

def safe_format_number(x):
    """ì•ˆì „í•œ ìˆ«ì í¬ë§·íŒ…"""
    try:
        if pd.isna(x) or x is None or x == "" or x == 0:
            return "-"
        
        # ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ìˆ«ìì¸ì§€ í™•ì¸
        x_str = str(x)
        if x_str.replace('.', '').replace('-', '').isdigit():
            num_val = float(x)
            if num_val > 0:
                return f"{int(num_val):,}"
        return "-"
    except (ValueError, TypeError, OverflowError):
        return "-"

def _merge_and_clean_data(related_df, volume_data, product_counts):
    """ë°ì´í„° ë³‘í•© ë° ì •ë¦¬"""
    try:
        # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ë³€í™˜
        if volume_data:
            volume_df = pd.DataFrame(volume_data)
            merged_df = pd.merge(related_df, volume_df, 
                               left_on='ì—°ê´€ ê²€ìƒ‰ì–´', right_on='relKeyword', how='left')
        else:
            merged_df = related_df.copy()
        
        # ìƒí’ˆìˆ˜ ë°ì´í„° ë³‘í•©
        if product_counts:
            product_count_df = pd.DataFrame(list(product_counts.items()), 
                                          columns=['ì—°ê´€ ê²€ìƒ‰ì–´', 'ìƒí’ˆìˆ˜'])
            merged_df = pd.merge(merged_df, product_count_df, on='ì—°ê´€ ê²€ìƒ‰ì–´', how='left')
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        column_mapping = {
            'monthlyPcQcCnt': 'PC ì›”ê°„ê²€ìƒ‰ìˆ˜',
            'monthlyMobileQcCnt': 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜',
            'compIdx': 'ê²½ìŸê°•ë„'
        }
        merged_df.rename(columns=column_mapping, inplace=True)
        
        # ìˆ«ì ì»¬ëŸ¼ ì•ˆì „í•˜ê²Œ ë³€í™˜
        numeric_columns = ['PC ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ìƒí’ˆìˆ˜', 'ê²½ìŸê°•ë„']
        for col in numeric_columns:
            if col in merged_df.columns:
                # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
                merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce').fillna(0)
                if col != 'ê²½ìŸê°•ë„':  # ê²½ìŸê°•ë„ëŠ” ì†Œìˆ˜ì  ìœ ì§€
                    merged_df[col] = merged_df[col].astype(int)
        
        # ê¸°ë³¸ ì»¬ëŸ¼ë“¤ë„ ì•ˆì „í•˜ê²Œ ë³€í™˜
        if 'ì–¸ê¸‰ íšŸìˆ˜' in merged_df.columns:
            merged_df['ì–¸ê¸‰ íšŸìˆ˜'] = pd.to_numeric(merged_df['ì–¸ê¸‰ íšŸìˆ˜'], errors='coerce').fillna(1).astype(int)
        if 'ìˆœìœ„' in merged_df.columns:
            merged_df['ìˆœìœ„'] = pd.to_numeric(merged_df['ìˆœìœ„'], errors='coerce').fillna(0).astype(int)
        
        # ì´ ê²€ìƒ‰ìˆ˜ ê³„ì‚°
        if 'PC ì›”ê°„ê²€ìƒ‰ìˆ˜' in merged_df.columns and 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜' in merged_df.columns:
            merged_df['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] = merged_df['PC ì›”ê°„ê²€ìƒ‰ìˆ˜'] + merged_df['ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜']
        
        return merged_df
        
    except Exception as e:
        logger.error(f"Data merge error: {str(e)}")
        # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
        return related_df.copy()

def _display_card_view(df, columns):
    """ì¹´ë“œí˜• ë³´ê¸° - ìŠ¤í¬ë¡¤ ì—†ì´ ë³´ê¸° í¸í•œ í˜•íƒœ"""
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    df_clean = df.drop_duplicates(subset=['ì—°ê´€ ê²€ìƒ‰ì–´'], keep='first').copy()
    df_clean = df_clean.sort_values('ì–¸ê¸‰ íšŸìˆ˜', ascending=False).reset_index(drop=True)
    df_clean['ìˆœìœ„'] = range(1, len(df_clean) + 1)
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì • - 20ê°œì”© í‘œì‹œ
    items_per_page = 20
    total_pages = max(1, (len(df_clean) - 1) // items_per_page + 1)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        # í˜ì´ì§€ ë²ˆí˜¸ë¥¼ 1ë¶€í„° ì‹œì‘í•˜ë„ë¡ ìˆ˜ì •
        if 'card_current_page' not in st.session_state:
            st.session_state.card_current_page = 1
            
        current_page = st.selectbox(
            "í˜ì´ì§€ ì„ íƒ",
            range(1, total_pages + 1),
            index=st.session_state.card_current_page - 1,
            format_func=lambda x: f"í˜ì´ì§€ {x} ({(x-1)*items_per_page + 1}-{min(x*items_per_page, len(df_clean))})",
            key="card_page_selector"
        )
        
        # í˜ì´ì§€ ë³€ê²½ ì‹œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.card_current_page = current_page
    
    # í˜„ì¬ í˜ì´ì§€ ë°ì´í„°
    start_idx = (current_page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, len(df_clean))
    page_data = df_clean.iloc[start_idx:end_idx]
    
    # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ - 2ì—´ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ì¡°ì •
    for i in range(0, len(page_data), 2):
        cols = st.columns(2)
        
        for j, col in enumerate(cols):
            if i + j < len(page_data):
                row = page_data.iloc[i + j]
                
                with col:
                    # ì»´íŒ©íŠ¸í•œ ì¹´ë“œ ë””ìì¸
                    st.markdown(f"""
                    <div style="background-color: #f8f9fa; padding: 0.8rem; border-radius: 0.4rem; margin-bottom: 0.5rem; border: 1px solid #e9ecef;">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div>
                                <h5 style="margin: 0; color: #1f77b4; font-size: 1.1rem;">#{row['ìˆœìœ„']} {row['ì—°ê´€ ê²€ìƒ‰ì–´']}</h5>
                                <p style="margin: 0.3rem 0 0 0; font-size: 0.9rem; color: #666;">
                                    ì–¸ê¸‰ <strong>{row['ì–¸ê¸‰ íšŸìˆ˜']}</strong>íšŒ
                                </p>
                            </div>
                        </div>
                    """, unsafe_allow_html=True)
                    
                    # ì¶”ê°€ ì§€í‘œë“¤ì„ ì‘ì€ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                    metrics_text = []
                    if 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' in row and pd.notna(row['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜']) and row['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'] > 0:
                        metrics_text.append(f"ê²€ìƒ‰ëŸ‰: {int(row['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜']):,}")
                    if 'ìƒí’ˆìˆ˜' in row and pd.notna(row['ìƒí’ˆìˆ˜']) and row['ìƒí’ˆìˆ˜'] > 0:
                        metrics_text.append(f"ìƒí’ˆ: {int(row['ìƒí’ˆìˆ˜']):,}ê°œ")
                    if 'ê²½ìŸê°•ë„' in row and pd.notna(row['ê²½ìŸê°•ë„']):
                        competition_level = "ë†’ìŒ" if row['ê²½ìŸê°•ë„'] > 70 else "ë³´í†µ" if row['ê²½ìŸê°•ë„'] > 40 else "ë‚®ìŒ"
                        metrics_text.append(f"ê²½ìŸ: {competition_level}")
                    
                    if metrics_text:
                        st.markdown(f"""
                        <div style="font-size: 0.8rem; color: #888; margin-top: 0.3rem;">
                            {' | '.join(metrics_text)}
                        </div>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown("</div>", unsafe_allow_html=True)
    
    # í˜ì´ì§€ ì •ë³´ í‘œì‹œ
    st.info(f"ì´ {len(df_clean)}ê°œ ì¤‘ {start_idx + 1}-{end_idx}ë²ˆì§¸ í‘œì‹œ | í˜ì´ì§€ {current_page}/{total_pages}")

def _display_table_view(df, columns):
    """ê°œì„ ëœ í…Œì´ë¸” ë³´ê¸° - í•„í„°ë§ ë° ì •ë ¬ ê¸°ëŠ¥ í¬í•¨"""
    try:
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        df_clean = df.drop_duplicates(subset=['ì—°ê´€ ê²€ìƒ‰ì–´'], keep='first').copy()
        
        # ë°ì´í„° íƒ€ì… ì•ˆì „ì„± í™•ë³´
        if 'ì–¸ê¸‰ íšŸìˆ˜' in df_clean.columns:
            df_clean['ì–¸ê¸‰ íšŸìˆ˜'] = pd.to_numeric(df_clean['ì–¸ê¸‰ íšŸìˆ˜'], errors='coerce').fillna(1).astype(int)
        
        # ì •ë ¬ ì‹œ ë°ì´í„° íƒ€ì… í™•ë³´
        df_clean = df_clean.sort_values('ì–¸ê¸‰ íšŸìˆ˜', ascending=False).reset_index(drop=True)
        df_clean['ìˆœìœ„'] = range(1, len(df_clean) + 1)
        
        st.markdown("#### í•„í„° ë° ì •ë ¬ ì˜µì…˜")
        
        filter_col1, filter_col2, filter_col3 = st.columns(3)
        
        with filter_col1:
            # ì–¸ê¸‰íšŸìˆ˜ í•„í„° - ì•ˆì „í•œ min/max ê°’ ê³„ì‚°
            try:
                min_val = max(1, int(df_clean['ì–¸ê¸‰ íšŸìˆ˜'].min())) if len(df_clean) > 0 else 1
                max_val = max(1, int(df_clean['ì–¸ê¸‰ íšŸìˆ˜'].max())) if len(df_clean) > 0 else 1
                
                # min_valê³¼ max_valì´ ê°™ì€ ê²½ìš° ì²˜ë¦¬
                if min_val == max_val:
                    min_mentions = min_val
                    st.write(f"ì–¸ê¸‰ íšŸìˆ˜: {min_val}")
                else:
                    min_mentions = st.slider(
                        "ìµœì†Œ ì–¸ê¸‰ íšŸìˆ˜",
                        min_value=min_val,
                        max_value=max_val,
                        value=min_val,
                        key="mentions_filter"
                    )
            except Exception as e:
                logger.error(f"Slider error: {str(e)}")
                min_mentions = 1
                st.write("ì–¸ê¸‰ íšŸìˆ˜ í•„í„°ë¥¼ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with filter_col2:
            # ê²€ìƒ‰ì–´ í•„í„°
            search_term = st.text_input("ê²€ìƒ‰ì–´ í•„í„°", placeholder="íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰...", key="search_filter")
        
        with filter_col3:
            # ì •ë ¬ ì˜µì…˜
            sort_options = {
                'ì–¸ê¸‰ íšŸìˆ˜ (ë‚´ë¦¼ì°¨ìˆœ)': ('ì–¸ê¸‰ íšŸìˆ˜', False),
                'ì–¸ê¸‰ íšŸìˆ˜ (ì˜¤ë¦„ì°¨ìˆœ)': ('ì–¸ê¸‰ íšŸìˆ˜', True),
                'ìˆœìœ„ (ì˜¤ë¦„ì°¨ìˆœ)': ('ìˆœìœ„', True),
                'ê°€ë‚˜ë‹¤ìˆœ': ('ì—°ê´€ ê²€ìƒ‰ì–´', True)
            }
            
            if 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' in df_clean.columns:
                sort_options.update({
                    'ê²€ìƒ‰ìˆ˜ (ë‚´ë¦¼ì°¨ìˆœ)': ('ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜', False),
                    'ê²€ìƒ‰ìˆ˜ (ì˜¤ë¦„ì°¨ìˆœ)': ('ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜', True)
                })
            
            sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", list(sort_options.keys()), key="sort_option")
        
        # í•„í„° ì ìš© - ì•ˆì „í•œ ë¹„êµ
        try:
            filtered_df = df_clean[df_clean['ì–¸ê¸‰ íšŸìˆ˜'] >= min_mentions].copy()
        except Exception as e:
            logger.error(f"Filter error: {str(e)}")
            filtered_df = df_clean.copy()
        
        if search_term:
            try:
                filtered_df = filtered_df[
                    filtered_df['ì—°ê´€ ê²€ìƒ‰ì–´'].str.contains(search_term, case=False, na=False)
                ]
            except Exception as e:
                logger.error(f"Search filter error: {str(e)}")
        
        # ì •ë ¬ ì ìš© - ì•ˆì „í•œ ì •ë ¬
        try:
            sort_column, ascending = sort_options[sort_by]
            if sort_column in filtered_df.columns:
                # ì •ë ¬ ì»¬ëŸ¼ íƒ€ì… í™•ë³´
                if sort_column in ['ì–¸ê¸‰ íšŸìˆ˜', 'ìˆœìœ„', 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜']:
                    filtered_df[sort_column] = pd.to_numeric(filtered_df[sort_column], errors='coerce').fillna(0)
                
                filtered_df = filtered_df.sort_values(sort_column, ascending=ascending).reset_index(drop=True)
                # ì •ë ¬ í›„ ìˆœìœ„ ì¬ì¡°ì •
                if sort_column == 'ì–¸ê¸‰ íšŸìˆ˜' and not ascending:
                    filtered_df['ìˆœìœ„'] = range(1, len(filtered_df) + 1)
        except Exception as e:
            logger.error(f"Sort error: {str(e)}")
            pass

        # í˜ì´ì§€ë„¤ì´ì…˜ - 20ê°œì”© í‘œì‹œ
        items_per_page = 20
        
        if len(filtered_df) == 0:
            st.warning("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        total_pages = max(1, (len(filtered_df) - 1) // items_per_page + 1)
        
        if total_pages > 1:
            if 'table_current_page' not in st.session_state:
                st.session_state.table_current_page = 1
                
            current_page = st.selectbox(
                f"í˜ì´ì§€ ì„ íƒ (ì´ {total_pages}í˜ì´ì§€)",
                range(1, total_pages + 1),
                index=st.session_state.table_current_page - 1,
                key="table_page_selector"
            )
            st.session_state.table_current_page = current_page
            
            start_idx = (current_page - 1) * items_per_page
            end_idx = min(start_idx + items_per_page, len(filtered_df))
            page_data = filtered_df.iloc[start_idx:end_idx].copy()
        else:
            page_data = filtered_df.copy()
            start_idx, end_idx = 0, len(filtered_df)
        
        st.markdown(f"#### ê²°ê³¼: {len(filtered_df)}ê°œ í‚¤ì›Œë“œ ë°œê²¬")
        styled_df = page_data[columns].copy()

        def fmt_num(x):
            try:
                v = float(x)
                return f"{int(v):,}" if v > 0 else "-"
            except Exception:
                return "-"

        for col in ['ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜', 'PC ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ìƒí’ˆìˆ˜']:
            if col in styled_df.columns:
                styled_df[col] = styled_df[col].apply(fmt_num)
        
        if 'ê²½ìŸê°•ë„' in styled_df.columns:
            def format_competition(x):
                try:
                    if pd.isna(x) or float(x) == 0:
                        return "-"
                    comp_value = float(x)
                    if comp_value >= 80:
                        return f"ë§¤ìš°ë†’ìŒ({comp_value:.0f})"
                    elif comp_value >= 60:
                        return f"ë†’ìŒ({comp_value:.0f})"
                    elif comp_value >= 40:
                        return f"ë³´í†µ({comp_value:.0f})"
                    elif comp_value >= 20:
                        return f"ë‚®ìŒ({comp_value:.0f})"
                    else:
                        return f"ë§¤ìš°ë‚®ìŒ({comp_value:.0f})"
                except Exception:
                    return "-"
            styled_df['ê²½ìŸê°•ë„'] = styled_df['ê²½ìŸê°•ë„'].apply(format_competition)
        
        st.dataframe(styled_df, use_container_width=True, hide_index=True, height=600)
        
        if total_pages > 1:
            st.info(f"{start_idx + 1}-{end_idx}ë²ˆì§¸ / ì´ {len(filtered_df)}ê°œ")
            
        # CSV ë‹¤ìš´ë¡œë“œ
        try:
            csv = filtered_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"naver_keyword_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error(f"CSV ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        logger.error(f"Table view display error: {str(e)}")
        st.error(f"í…Œì´ë¸” ë·°ë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


def _display_final_results(df):
    """ìµœì¢… ê²°ê³¼ í‘œì‹œ (ê°œì„ ëœ ë²„ì „)"""
    st.subheader("ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    
    display_columns = ['ìˆœìœ„', 'ì—°ê´€ ê²€ìƒ‰ì–´', 'ì–¸ê¸‰ íšŸìˆ˜']
    if 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜' in df.columns:
        display_columns.extend(['PC ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜', 'ì´ ì›”ê°„ê²€ìƒ‰ìˆ˜'])
    if 'ìƒí’ˆìˆ˜' in df.columns:
        display_columns.append('ìƒí’ˆìˆ˜')
    if 'ê²½ìŸê°•ë„' in df.columns:
        display_columns.append('ê²½ìŸê°•ë„')
    
    available_columns = [col for col in display_columns if col in df.columns]
    
    tab1, tab2 = st.tabs(["ì¹´ë“œí˜• ë³´ê¸°", "í…Œì´ë¸” ë³´ê¸°"])
    with tab1:
        _display_card_view(df, available_columns)
    with tab2:
        _display_table_view(df, available_columns)

def main():
    # Streamlit í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="CHURIXX Title Maker Analyze",
        page_icon="ğŸ›’",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ì»¤ìŠ¤í…€ CSS
    st.markdown("""
    <style>
    .main-header { font-size: 2.5rem; font-weight: bold; color: #1f77b4; text-align: center; margin-bottom: 2rem; cursor: pointer; text-decoration: none; }
    .main-header:hover { color: #0d5aa7; text-decoration: none; }
    .metric-card { background-color: #f0f2f6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem; }
    </style>
    """, unsafe_allow_html=True)

    # í™ˆ ë²„íŠ¼ (ìƒíƒœ ì´ˆê¸°í™”)
    if st.button("", key="home_button_hidden", help="í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        for key in list(st.session_state.keys()):
            if key.startswith(('card_', 'table_', 'last_keyword', 'api_')):
                del st.session_state[key]
        st.rerun()

    st.markdown("""
    <div onclick="document.querySelector('[data-testid=\\'home_button_hidden\\']').click()" 
         class="main-header">
        CHURIXX Title Maker Analyze
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### ë„¤ì´ë²„ ì‡¼í•‘ í‚¤ì›Œë“œ ì—°ê´€ê²€ìƒ‰ì–´ì™€ ê²€ìƒ‰ëŸ‰ì„ ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤!")

    analyzer = NaverKeywordAnalyzer()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ë¶„ì„ ì„¤ì •")

        # ë°ì´í„° ì†ŒìŠ¤ í† ê¸€
        source = st.radio(
            "ë°ì´í„° ì†ŒìŠ¤",
            ["ì‹¤ì‹œê°„ 1í˜ì´ì§€(ê¶Œì¥)", "Open API ê·¼ì‚¬ì¹˜"],
            index=0,
            help="ì‹¤ì‹œê°„: ì‹¤ì œ ë„¤ì´ë²„ì‡¼í•‘ 1í˜ì´ì§€ 1~40ìœ„ / ê·¼ì‚¬ì¹˜: Open API ìœ ì‚¬ë„ ì •ë ¬"
        )
        
        keyword = st.text_input(
            'í‚¤ì›Œë“œ ì…ë ¥', 
            value='',
            help="ë¶„ì„í•˜ê³  ì‹¶ì€ ìƒí’ˆ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ë°˜íŒ”í‹°, ë…¸íŠ¸ë¶, ìš´ë™í™”"
        )
        
        st.subheader("ë¶„ì„ ì˜µì…˜")
        show_basic_chart = st.checkbox("ê¸°ë³¸ ì°¨íŠ¸ í‘œì‹œ", value=True)
        show_comparison_chart = st.checkbox("ë¹„êµ ì°¨íŠ¸ í‘œì‹œ", value=False)
        show_search_volume = st.checkbox("ê²€ìƒ‰ëŸ‰ ë°ì´í„° í¬í•¨", value=True)
        
        max_keywords_for_volume = st.slider(
            "ê²€ìƒ‰ëŸ‰ ì¡°íšŒí•  í‚¤ì›Œë“œ ìˆ˜",
            min_value=5, max_value=20, value=10,
            help="ë” ë§ì€ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ë©´ ì‹œê°„ì´ ë” ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        analyze_button = st.button('ë¶„ì„ ì‹œì‘', type="primary", use_container_width=True)

    if 'last_keyword' not in st.session_state:
        st.session_state.last_keyword = ''
    
    keyword_changed = (keyword != st.session_state.last_keyword and keyword.strip() != '')
    should_analyze = analyze_button or keyword_changed
    
    if keyword:
        st.session_state.last_keyword = keyword

    # ë©”ì¸ ë¶„ì„ ë¡œì§
    if should_analyze and keyword:
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        try:
            status_text.text('ì—°ê´€ ê²€ìƒ‰ì–´ ë¶„ì„ ì¤‘...')
            progress_bar.progress(20)

            if source.startswith("ì‹¤ì‹œê°„"):
                # This part is missing in the provided appcud.py, assuming it's meant to be here
                # related_df = analyzer.get_related_keywords_realtime(keyword) 
                # For now, using the get_related_keywords from the class
                related_df = analyzer.get_related_keywords(keyword) 
                time.sleep(random.uniform(0.6, 1.2))  # Add random sleep if real-time scraping is involved
            else:
                related_df = analyzer.get_related_keywords(keyword)

            if not related_df.empty:
                related_df = related_df.copy()
                # Ensure numeric conversion for 'ìˆœìœ„' and 'ì–¸ê¸‰ íšŸìˆ˜'
                related_df['ìˆœìœ„'] = pd.to_numeric(related_df['ìˆœìœ„'], errors='coerce').fillna(0).astype(int)
                related_df['ì–¸ê¸‰ íšŸìˆ˜'] = pd.to_numeric(related_df['ì–¸ê¸‰ íšŸìˆ˜'], errors='coerce').fillna(1).astype(int)
                related_df['ì—°ê´€ ê²€ìƒ‰ì–´'] = related_df['ì—°ê´€ ê²€ìƒ‰ì–´'].astype(str)
                related_df = related_df[related_df['ì–¸ê¸‰ íšŸìˆ˜'] > 0].reset_index(drop=True)
                related_df['ìˆœìœ„'] = range(1, len(related_df) + 1)
            
            if not related_df.empty:
                progress_bar.progress(40)
                
                results_container = st.container()
                with results_container:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ë°œê²¬ëœ ì—°ê´€ ê²€ìƒ‰ì–´", f"{len(related_df)}ê°œ")
                    with col2:
                        st.metric("í‰ê·  ì–¸ê¸‰ íšŸìˆ˜", f"{related_df['ì–¸ê¸‰ íšŸìˆ˜'].mean():.1f}")
                    with col3:
                        st.metric("ìµœê³  ì–¸ê¸‰ íšŸìˆ˜", f"{related_df['ì–¸ê¸‰ íšŸìˆ˜'].max()}")
                
                chart_container = st.container()
                with chart_container:
                    if show_basic_chart:
                        basic_chart = create_enhanced_chart(related_df)
                        if basic_chart:
                            st.plotly_chart(basic_chart, use_container_width=True)
                
                if show_search_volume:
                    status_text.text('ê²€ìƒ‰ëŸ‰ ë° ìƒí’ˆìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...')
                    progress_bar.progress(60)
                    
                    related_keywords = related_df['ì—°ê´€ ê²€ìƒ‰ì–´'].head(max_keywords_for_volume).tolist()
                    product_counts = analyzer.get_product_count_for_keywords(related_keywords)
                    progress_bar.progress(70)
                    
                    all_volume_data = []
                    keyword_batches = [related_keywords[i:i + 5] for i in range(0, len(related_keywords), 5)]
                    for i, batch in enumerate(keyword_batches):
                        keywords_str = ','.join(batch)
                        search_volume_data = analyzer.get_search_volume(keywords_str)
                        if search_volume_data and 'keywordList' in search_volume_data:
                            all_volume_data.extend(search_volume_data['keywordList'])
                        progress_bar.progress(70 + (i + 1) * 20 // len(keyword_batches))
                        if i < len(keyword_batches) - 1:
                            time.sleep(1)
                    
                    final_df = _merge_and_clean_data(related_df, all_volume_data, product_counts)

                    if show_comparison_chart:
                        comparison_chart = create_comparison_chart(final_df)
                        if comparison_chart:
                            st.plotly_chart(comparison_chart, use_container_width=True)
                    
                    _display_final_results(final_df)
                
                if not show_search_volume:
                    related_keywords = related_df['ì—°ê´€ ê²€ìƒ‰ì–´'].tolist()
                    product_counts = analyzer.get_product_count_for_keywords(related_keywords)
                    if product_counts:
                        product_count_df = pd.DataFrame(list(product_counts.items()), columns=['ì—°ê´€ ê²€ìƒ‰ì–´', 'ìƒí’ˆìˆ˜'])
                        final_df = pd.merge(related_df, product_count_df, on='ì—°ê´€ ê²€ìƒ‰ì–´', how='left')
                        final_df['ìƒí’ˆìˆ˜'] = final_df['ìƒí’ˆìˆ˜'].fillna(0).astype(int)
                        st.subheader("ì—°ê´€ ê²€ìƒ‰ì–´ + ìƒí’ˆìˆ˜ ë¶„ì„ ê²°ê³¼")
                        st.dataframe(final_df, use_container_width=True, hide_index=True)
                    else:
                        st.subheader("ì—°ê´€ ê²€ìƒ‰ì–´ ë¶„ì„ ê²°ê³¼")
                        st.dataframe(related_df, use_container_width=True, hide_index=True)
                
                progress_bar.progress(100)
                status_text.text('ë¶„ì„ ì™„ë£Œ!')
                time.sleep(0.6)
                progress_container.empty()
            else:
                progress_container.empty()
                st.error("ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                
        except Exception as e:
            progress_container.empty()
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logger.error(f"Analysis error: {str(e)}")
            
    elif should_analyze and not keyword:
        st.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!")
        st.subheader("ì¸ê¸° í‚¤ì›Œë“œ ì œì•ˆ")
        sample_keywords = ['ë°˜íŒ”í‹°', 'ë…¸íŠ¸ë¶', 'ìš´ë™í™”', 'í™”ì¥í’ˆ', 'í•¸ë“œí°ì¼€ì´ìŠ¤', 'í…€ë¸”ëŸ¬', 'ë°±íŒ©']
        cols = st.columns(len(sample_keywords))
        for i, sample in enumerate(sample_keywords):
            with cols[i]:
                if st.button(sample, key=f"sample_{i}"):
                    st.session_state.last_keyword = sample
                    st.rerun()

    with st.expander("ì‚¬ìš©ë²• ë° ë„ì›€ë§"):
        st.markdown("""
        ### ì‚¬ìš©ë²•
        1. **í‚¤ì›Œë“œ ì…ë ¥**: ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•˜ê³  ì‹¶ì€ ìƒí’ˆëª…ì´ë‚˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”
        2. **ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ**: ì‹¤ì‹œê°„ 1í˜ì´ì§€(ê¶Œì¥) ë˜ëŠ” Open API ê·¼ì‚¬ì¹˜
        3. **ë¶„ì„ ì‹¤í–‰**: 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ í´ë¦­
        4. **ê²°ê³¼ í™•ì¸**: ì¹´ë“œí˜•/í…Œì´ë¸” íƒ­ìœ¼ë¡œ ì„¸ë¶€ í™•ì¸ ë° CSV ë‹¤ìš´ë¡œë“œ
        """)

if __name__ == "__main__":
    main()